{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DEEP PROJECT-Final(Public).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mreza2370/Autism_detection/blob/main/Appendix15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyIC0N2zF151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7dccf67e-53f1-4d50-f068-4d9b9cdd4520"
      },
      "source": [
        "# This Code Prepares 1 million data\n",
        "number=100\n",
        "#prepare x and y \n",
        "import random\n",
        "x_points=[]\n",
        "y_points=[0 for i in range(100)]\n",
        "for i in range(1,200,2):\n",
        "    x_points.append(i)\n",
        "    \n",
        "    \n",
        "# data including different classes    \n",
        "dataA=[]\n",
        "dataB=[]\n",
        "dataC=[]\n",
        "dataD=[]\n",
        "dataE=[]\n",
        "\n",
        "label=[[[1,0,0,0,0] for i in range(number)],[[0,1,0,0,0] for i in range(number)],[[0,0,1,0,0] for i in range(number)],[[0,0,0,1,0] for i in range(number)],[[0,0,0,0,1] for i in range(number)]]\n",
        "\n",
        "\"\"\"\n",
        "# this code is written to show the non-zero elements in every data\n",
        "n=0\n",
        "for y in data2[5]:\n",
        "    if y!=0:\n",
        "        n+=1\n",
        "\"\"\"        \n",
        "\"\"\"        \n",
        "#plot the gausiian noise        \n",
        "import numpy as np\n",
        "s = np.random.normal(0, 1, 1000)    \n",
        "#cold use s instead of x   \n",
        "\n",
        "x=[]\n",
        "for i in range(1000):\n",
        "    x.append(random.gauss(0,1))\n",
        "x= np.asarray(x)\n",
        "\n",
        "sigma=1\n",
        "mu=0\n",
        "import matplotlib.pyplot as plt\n",
        "count, bins, ignored = plt.hist(x, 30, density=True)\n",
        "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *np.exp( - (bins - mu)**2 / (2 * sigma**2) ),linewidth=2, color='r')\n",
        "plt.show()\n",
        "\"\"\"\n",
        "\n",
        "############################################################\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "#plot every data\n",
        "import matplotlib.pyplot as plt\n",
        "for i in range(100):\n",
        "    plt.figure(i)\n",
        "    #plt.subplot(i+100)\n",
        "    plt.plot(x_points,dataA[i],'r*')\n",
        "    plt.savefig('results/A/ %s.png'%i)\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(x_points,data_ex[1],'r*')\n",
        "plt.show()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def classA(y_points):\n",
        "    y_dtat=y_points.copy()\n",
        "    num=random.randint(0,19)\n",
        "    s_num=[]\n",
        "    selected=[]\n",
        "    for i in range(num):\n",
        "        rand=random.randint(0,99)\n",
        "        while(True):\n",
        "            if rand not in selected:\n",
        "                selected.append(rand)\n",
        "                s_num.append(rand)\n",
        "                break\n",
        "            else:\n",
        "                rand=random.randint(0,99)\n",
        "    for s in s_num:\n",
        "        y_dtat[s]=random.gauss(0,1)\n",
        "    return(y_dtat)\n",
        "        \n",
        "def classB(y_points):\n",
        "    y_dtat=y_points.copy()\n",
        "    num=random.randint(20,39)\n",
        "    s_num=[]\n",
        "    selected=[]\n",
        "    for i in range(num):\n",
        "        rand=random.randint(0,99)\n",
        "        while(True):\n",
        "            if rand not in selected:\n",
        "                selected.append(rand)\n",
        "                s_num.append(rand)\n",
        "                break\n",
        "            else:\n",
        "                rand=random.randint(0,99)\n",
        "    for s in s_num:\n",
        "        y_dtat[s]=random.gauss(0,1)\n",
        "    return y_dtat\n",
        "        \n",
        "        \n",
        "def classC(y_points):\n",
        "    y_dtat=y_points.copy()\n",
        "    num=random.randint(40,59)\n",
        "    s_num=[]\n",
        "    selected=[]\n",
        "    for i in range(num):\n",
        "        rand=random.randint(0,99)\n",
        "        while(True):\n",
        "            if rand not in selected:\n",
        "                selected.append(rand)\n",
        "                s_num.append(rand)\n",
        "                break\n",
        "            else:\n",
        "                rand=random.randint(0,99)\n",
        "    for s in s_num:\n",
        "        y_dtat[s]=random.gauss(0,1)\n",
        "    return y_dtat\n",
        "        \n",
        "def classD(y_points):\n",
        "    y_dtat=y_points.copy()\n",
        "    num=random.randint(60,79)\n",
        "    s_num=[]\n",
        "    selected=[]\n",
        "    for i in range(num):\n",
        "        rand=random.randint(0,99)\n",
        "        while(True):\n",
        "            if rand not in selected:\n",
        "                selected.append(rand)\n",
        "                s_num.append(rand)\n",
        "                break\n",
        "            else:\n",
        "                rand=random.randint(0,99)\n",
        "    for s in s_num:\n",
        "        y_dtat[s]=random.gauss(0,1)\n",
        "    return y_dtat\n",
        "        \n",
        "        \n",
        "def classE(y_points):\n",
        "    y_dtat=y_points.copy()\n",
        "    num=random.randint(80,99)\n",
        "    s_num=[]\n",
        "    selected=[]\n",
        "    for i in range(num):\n",
        "        rand=random.randint(0,99)\n",
        "        while(True):\n",
        "            if rand not in selected:\n",
        "                selected.append(rand)\n",
        "                s_num.append(rand)\n",
        "                break\n",
        "            else:\n",
        "                rand=random.randint(0,99)\n",
        "    for s in s_num:\n",
        "        y_dtat[s]=random.gauss(0,1)\n",
        "    return y_dtat\n",
        "    \n",
        "    \n",
        "#Create class\n",
        "# i shows the number of data in each class\n",
        "\n",
        "for i in range(number):\n",
        "    outp=classA(y_points)\n",
        "    dataA.append(outp)\n",
        "for i in range(number):\n",
        "    outp=classB(y_points)\n",
        "    dataB.append(outp)\n",
        "for i in range(number):\n",
        "    outp=classC(y_points)\n",
        "    dataC.append(outp)\n",
        "for i in range(number):\n",
        "    outp=classD(y_points)\n",
        "    dataD.append(outp)\n",
        "for i in range(number):\n",
        "    outp=classE(y_points)\n",
        "    dataE.append(outp)\n",
        "\n",
        "data=[dataA,dataB,dataC,dataD,dataE]\n",
        "\"\"\"\n",
        "# Write data on Csv\n",
        "import csv\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "current_date = str(date.today())\n",
        "now = datetime.now()\n",
        "current_date = str(date.today())\n",
        "now = datetime.now()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "current_time_copy=list(current_time)\n",
        "for p,c in enumerate(current_time):\n",
        "    if c==':':\n",
        "        c='-'\n",
        "        current_time_copy[p]=c\n",
        "current_time_copy=\"\".join(current_time_copy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "if not os.path.exists('results'):\n",
        "    os.mkdir('results') \n",
        "for dat_ind,dat in enumerate(data):    \n",
        "    date_and_time=current_date+'  '+current_time_copy+'  '+str(dat_ind+1)\n",
        "    with open('results/Results %s.csv'%date_and_time, mode='w',newline='') as employee_file:\n",
        "        employee_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "        for da in dat:\n",
        "             employee_writer.writerow(da)\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "data=np.asarray(data)\n",
        "label=np.asarray(label)\n",
        "data=data.reshape(5*number,100)\n",
        "label=label.reshape(5*number,5)\n",
        "\n",
        "\n",
        "data = data.astype('float32')\n",
        "label = label.astype('float32')\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "length=len(data[0:])\n",
        "rows=[j for j in range(length)]\n",
        "data_ex=data.copy()\n",
        "lebel_ex=label.copy()\n",
        "selected_rows=[]\n",
        "i=0\n",
        "while(True):\n",
        "    while(True):\n",
        "        length2=len(rows)\n",
        "        random_num=random.randint(0,length2-1)\n",
        "        random_row=rows[random_num]\n",
        "        if random_row not in selected_rows:\n",
        "            selected_rows.append(random_row)\n",
        "            rows.remove(rows[random_num])\n",
        "            break\n",
        "     \n",
        "    data_ex[i]=data[random_row]\n",
        "    lebel_ex[i]=label[random_row]\n",
        "    i+=1\n",
        "    if i%10000==0:\n",
        "      print(i)\n",
        "    if i==length:\n",
        "        break   \n",
        "\n",
        "\n",
        "\n",
        "print('##############################')\n",
        "\n",
        "\n",
        "data_final=data_ex.copy()\n",
        "for i in range(len(data_ex[0:])):\n",
        "    average=max(data_ex[i])-min(data_ex[i])\n",
        "    if average==0:\n",
        "        pass\n",
        "    else:\n",
        "        data_final[i]=data_ex[i]/average\n",
        "    if i%10000==0:\n",
        "        print(i)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##############################\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD1nq05LhNsR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "4cf001b3-5993-4c9f-d340-11593a5e94a8"
      },
      "source": [
        "data_final[120]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04870022,  0.        , -0.06285232,  0.        ,  0.        ,\n",
              "        0.        ,  0.        , -0.2608841 ,  0.        ,  0.        ,\n",
              "        0.        ,  0.        ,  0.        ,  0.01831751,  0.        ,\n",
              "        0.        , -0.30856624,  0.10408894,  0.        ,  0.        ,\n",
              "        0.35265788,  0.18658057,  0.        , -0.24462447,  0.        ,\n",
              "        0.26117128,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "        0.18174316,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "        0.        , -0.46241695,  0.        ,  0.        ,  0.        ,\n",
              "       -0.06157754, -0.17883262,  0.        ,  0.        ,  0.        ,\n",
              "        0.        , -0.06813992, -0.08787281,  0.        ,  0.        ,\n",
              "       -0.12680788,  0.        , -0.02762663, -0.03612194, -0.43097514,\n",
              "        0.        ,  0.27215528,  0.1173984 ,  0.        ,  0.        ,\n",
              "        0.19181421,  0.03887103,  0.        , -0.10352807,  0.        ,\n",
              "        0.        ,  0.18830363, -0.17372292,  0.        ,  0.        ,\n",
              "        0.00361464,  0.        , -0.42652553,  0.        ,  0.        ,\n",
              "        0.        ,  0.        ,  0.        ,  0.53758305, -0.13303642,\n",
              "       -0.03530711,  0.        ,  0.05787656, -0.22415334,  0.        ,\n",
              "        0.06963852,  0.09633016,  0.1596097 ,  0.16529629,  0.        ,\n",
              "        0.        ,  0.        , -0.24101269, -0.1379421 , -0.25326708,\n",
              "        0.        ,  0.        ,  0.        , -0.0184265 ,  0.        ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGrHDhiXhb3r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1220313-4fbc-42cd-8abe-eac860de7d09"
      },
      "source": [
        "lebel_ex[120]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw-6e12l3BsO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lFvmeuYE6KI"
      },
      "source": [
        "# Save data in drive\n",
        "np.savetxt('drive/My Drive/data_final[500th].txt',data_final)\n",
        "np.savetxt('drive/My Drive/lebel_ex[500th].txt',lebel_ex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc8_L-LrvILY"
      },
      "source": [
        "# show conected GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CUo7xQhHIMV"
      },
      "source": [
        "# Load the data from drive\n",
        "import numpy as np\n",
        "data_final = np.loadtxt('drive/My Drive/data_final[1m].txt')\n",
        "lebel_ex = np.loadtxt('drive/My Drive/lebel_ex[1m].txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfMtXpqkc5Ht"
      },
      "source": [
        "# Creating our model (FC)\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import SGD\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "myModel = Sequential()\n",
        "myModel.add(Dense(90, activation='relu', input_shape=(100,)))\n",
        "myModel.add(Dropout(20))\n",
        "myModel.add(Dense(90, activation='relu'))\n",
        "myModel.add(Dropout(20))\n",
        "myModel.add(Dense(90, activation='relu'))\n",
        "myModel.add(BatchNormalization())\n",
        "myModel.add(Dense(50, activation='relu'))\n",
        "myModel.add(Dropout(20))\n",
        "myModel.add(Dense(25, activation='relu'))\n",
        "myModel.add(BatchNormalization())\n",
        "myModel.add(Dense(5, activation='softmax'))\n",
        "myModel.add(Dense(5, activation='softmax'))\n",
        "\n",
        "from keras.utils import plot_model\n",
        "plot_model(myModel, to_file='model.png',show_shapes=True,show_layer_names=True,expand_nested =True,rankdir)\n",
        "\n",
        "myModel.summary()\n",
        "myModel.compile(optimizer='Nadam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "myModel.fit(data_final,lebel_ex, epochs=600,shuffle=True,batch_size=500, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzmR607mRuGE"
      },
      "source": [
        "# Preparing data for CNN\n",
        "data_final = data_final.reshape(1000000,10,10, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaKWyU9RRvgx"
      },
      "source": [
        "#==================================================\n",
        "# Creating our model (Tested CNN)\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "import keras\n",
        "myInput=layers.Input(shape=(10,10,1))\n",
        "conv1 = layers.Conv2D(16, 3, activation='selu', padding='same', strides=2)(myInput)\n",
        "conv2 = layers.Conv2D(32, 3, activation='selu', padding='same', strides=2)(conv1)\n",
        "flat = layers.Flatten()(conv2)\n",
        "out_layer = layers.Dense(5, activation='softmax')(flat)\n",
        "\n",
        "myModel = Model(myInput, out_layer)\n",
        "\n",
        "myModel.summary()\n",
        "myModel.compile(optimizer=keras.optimizers.Nadam(), loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "#==================================================\n",
        "# Train our model\n",
        "myModel.fit(data_final, lebel_ex, batch_size=500, epochs=300, validation_split=0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3M3VVm2eBI9"
      },
      "source": [
        "#==================================================\n",
        "# Creating our model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout,Flatten,Conv2D,MaxPool2D\n",
        "from keras.optimizers import Nadam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "myModel = Sequential()\n",
        "\n",
        "myModel.add(Conv2D(16, 2, activation='relu', padding='same', strides=1,input_shape=(10,10,1)))\n",
        "myModel.add(Conv2D(64, 2, activation='relu', padding='same', strides=1))\n",
        "myModel.add(Conv2D(64, 2, activation='relu', padding='same', strides=1))\n",
        "myModel.add(MaxPool2D(pool_size=1,strides=None,padding='same'))\n",
        "myModel.add(Conv2D(80, 2, activation='relu', padding='same', strides=1))\n",
        "myModel.add(Conv2D(80, 2, activation='relu', padding='same', strides=1))\n",
        "myModel.add(MaxPool2D(pool_size=1,strides=None,padding='same'))\n",
        "myModel.add(Conv2D(80, 2, activation='relu', padding='same', strides=1))\n",
        "\n",
        "myModel.add(Flatten())\n",
        "\n",
        "myModel.add(Dense(800, activation='relu'))\n",
        "myModel.add(Dense(80, activation='relu'))\n",
        "myModel.add(Dense(5, activation='softmax'))\n",
        "myModel.summary()\n",
        "\n",
        "myModel.compile(optimizer=Nadam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#==================================================\n",
        "# Train our model\n",
        "myModel.fit(data_final, lebel_ex, batch_size=500, epochs=600, validation_split=0.2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qXx5e8_ccfI"
      },
      "source": [
        "#==================================================\n",
        "# Creating our model\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout,Flatten,Conv2D,MaxPool2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.utils import plot_model\n",
        "\n",
        "myModel = Sequential()\n",
        "\n",
        "myModel.add(Conv2D(16, 2, activation='selu', padding='same', strides=1,input_shape=(10,10,1)))\n",
        "myModel.add(Conv2D(64, 2, activation='selu', padding='same', strides=1))\n",
        "myModel.add(Conv2D(64, 2, activation='selu', padding='same', strides=1))\n",
        "myModel.add(MaxPool2D(pool_size=1,strides=None,padding='same'))\n",
        "myModel.add(Conv2D(80, 2, activation='selu', padding='same', strides=1))\n",
        "myModel.add(Conv2D(80, 2, activation='selu', padding='same', strides=1))\n",
        "myModel.add(MaxPool2D(pool_size=1,strides=None,padding='same'))\n",
        "myModel.add(Conv2D(80, 2, activation='selu', padding='same', strides=1))\n",
        "\n",
        "\n",
        "myModel.add(Flatten())\n",
        "\n",
        "\n",
        "myModel.add(Dense(90, activation='relu'))\n",
        "myModel.add(Dropout(20))\n",
        "myModel.add(BatchNormalization())\n",
        "myModel.add(Dense(90, activation='relu'))\n",
        "myModel.add(Dropout(20))\n",
        "myModel.add(BatchNormalization())\n",
        "myModel.add(Dense(90, activation='relu'))\n",
        "myModel.add(Dropout(20))\n",
        "myModel.add(BatchNormalization())\n",
        "myModel.add(Dense(50, activation='relu'))\n",
        "myModel.add(Dropout(20))\n",
        "myModel.add(BatchNormalization())\n",
        "myModel.add(Dense(25, activation='relu'))\n",
        "myModel.add(Dropout(20))\n",
        "myModel.add(BatchNormalization())\n",
        "myModel.add(Dense(5, activation='softmax'))\n",
        "myModel.add(Dense(5, activation='softmax'))\n",
        "\n",
        "myModel.summary()\n",
        "plot_model(myModel, to_file='model2.png',show_shapes=True,expand_nested=True)\n",
        "myModel.compile(optimizer=keras.optimizers.Nadam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#==================================================\n",
        "# Train our model\n",
        "myModel.fit(data_final, lebel_ex, batch_size=500, epochs=600, validation_split=0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6L9lUC1gJAg"
      },
      "source": [
        "#==================================================\n",
        "# Creating our model\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout,Flatten,Conv2D,MaxPool2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.utils import plot_model\n",
        "\n",
        "myModel = Sequential()\n",
        "myModel.add(Conv2D(16, 2, activation='relu', padding='same', strides=1,input_shape=(10,10,1)))\n",
        "myModel.add(Conv2D(64, 2, activation='relu', padding='same', strides=1))\n",
        "myModel.add(Conv2D(64, 2, activation='relu', padding='same', strides=1))\n",
        "myModel.add(MaxPool2D(pool_size=1,strides=None,padding='same'))\n",
        "myModel.add(Conv2D(80, 2, activation='relu', padding='same', strides=1))\n",
        "myModel.add(Conv2D(80, 2, activation='relu', padding='same', strides=1))\n",
        "myModel.add(MaxPool2D(pool_size=1,strides=None,padding='same'))\n",
        "myModel.add(Conv2D(80, 2, activation='relu', padding='same', strides=1))\n",
        "\n",
        "\n",
        "myModel.add(Flatten())\n",
        "\n",
        "\n",
        "myModel.add(Dense(90, activation='relu'))\n",
        "myModel.add(Dropout(20))\n",
        "myModel.add(BatchNormalization())\n",
        "myModel.add(Dense(90, activation='relu'))\n",
        "myModel.add(Dropout(20))\n",
        "myModel.add(BatchNormalization())\n",
        "myModel.add(Dense(90, activation='relu'))\n",
        "myModel.add(Dropout(20))\n",
        "myModel.add(BatchNormalization())\n",
        "myModel.add(Dense(50, activation='relu'))\n",
        "myModel.add(Dropout(20))\n",
        "myModel.add(BatchNormalization())\n",
        "myModel.add(Dense(25, activation='relu'))\n",
        "myModel.add(Dropout(20))\n",
        "myModel.add(BatchNormalization())\n",
        "myModel.add(Dense(5, activation='softmax'))\n",
        "myModel.add(Dense(5, activation='softmax'))\n",
        "\n",
        "myModel.summary()\n",
        "plot_model(myModel, to_file='model2.png',show_shapes=True,expand_nested=True)\n",
        "myModel.compile(optimizer=keras.optimizers.Nadam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#==================================================\n",
        "# Train our model\n",
        "myModel.fit(data_final, lebel_ex, batch_size=500, epochs=600, validation_split=0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctx_2PqQ0phv"
      },
      "source": [
        "myModel.save('drive/My Drive/1m[40e_non_shuffle_nn7_99_89].h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeuXx7u9gf4B"
      },
      "source": [
        "from keras.models import load_model\n",
        "myModel=load_model('drive/My Drive/1m[40e_non_shuffle_nn7_99_89].h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HySKpi1RhBgH"
      },
      "source": [
        "from keras.optimizers import Nadam\n",
        "myModel.compile(optimizer=Nadam(lr=0.000000000000001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "myModel.fit(data_final,lebel_ex, batch_size=500, epochs=40, validation_split=0.2,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F00aZE4ORa2C"
      },
      "source": [
        "myModel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88b767I3-qD0"
      },
      "source": [
        "# Evaluation\n",
        "#test_loss, test_acc = myModel.evaluate(data_final,lebel_ex)\n",
        "test_labels_p = myModel.predict(data_final)\n",
        "import numpy as np\n",
        "test_labels_p = np.argmax(test_labels_p, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1sTI8le7885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc22075b-b1f5-4f2f-90bb-52f35cdb2392"
      },
      "source": [
        "test_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9986600012683868"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUgoudejHLiC"
      },
      "source": [
        "def evaluate(lebel_ex,test_labels_p):\n",
        "  import sys\n",
        "  if len(lebel_ex)!=len(test_labels_p):\n",
        "    return('Error sizes dont match')\n",
        "    #sys.exit()\n",
        "  Tp=0\n",
        "  Fp=0\n",
        "  #length=len(lebel_ex)/10\n",
        "  #process=0\n",
        "  for i in range(len(lebel_ex)):\n",
        "    if lebel_ex[i].argmax()!=test_labels_p[i]:\n",
        "        Fp+=1\n",
        "    else:\n",
        "        Tp+=1\n",
        "   # if (i+1)%length==0:\n",
        "     # process+=1\n",
        "      #processed=process*10\n",
        "      #print('%s percents done'%processed)\n",
        "  recall=Tp/len(test_labels_p)\n",
        "  accuracy=recall\n",
        "  precision=Tp/(Tp+Fp)\n",
        "  F1=(2*(precision*recall))/(precision+recall)\n",
        "  print('True Positives : ',Tp,'  ','False Positives : ',Fp)\n",
        "  print('Recall :',recall)\n",
        "  print('accuracy :',accuracy)\n",
        "  print('precision :',precision)\n",
        "  print('F1 measurement :',F1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajaSADLHLKkc"
      },
      "source": [
        "evaluate(lebel_ex,test_labels_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNpu9E9mU1CQ"
      },
      "source": [
        "# Pre-Processing\n",
        "        \n",
        "\n",
        "    \n",
        "def equalize(t,a):\n",
        "  ta= len(t)-len(a)\n",
        "  at= len(a)-len(t)\n",
        "  if ta>0:\n",
        "        t=equalize_matrix2(t,ta,a)\n",
        "  elif at>0:\n",
        "        t=equalize_matrix(t,at,a)\n",
        "  else:\n",
        "        pass\n",
        "  \n",
        "  return[t,a]\n",
        "  \n",
        "  \n",
        "def distance(a,b):\n",
        "  if len(a)==len(b):\n",
        "      d= len(a)\n",
        "      dis_matrix=[]\n",
        "      for num in range(d):\n",
        "          single_dis=abs(a[num]-b[num])\n",
        "          dis_matrix.append(single_dis)\n",
        "      return(dis_matrix)\n",
        "      \n",
        "  else:\n",
        "      raise NameError('given lists dont have same length') \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def equalize_matrix2(matrix,number,compare_matrix):\n",
        "    e_matrix=matrix.copy()\n",
        "    import random\n",
        "    import math\n",
        "    import numpy as np\n",
        "    conditions = math.factorial(len(e_matrix))/(math.factorial(number)*math.factorial(len(e_matrix)-number))\n",
        "    samples=[]\n",
        "    all_t_matrixes=[]\n",
        "    dis_value=[]\n",
        "    num_e_matrix=[i for i in range(len(e_matrix))]\n",
        "    while(True):\n",
        "          x=random.sample(num_e_matrix,number)\n",
        "          x.sort()\n",
        "          if x not in samples:\n",
        "                samples.append(x)\n",
        "          if len(samples)==conditions:\n",
        "                break\n",
        "    for sample in samples:\n",
        "          t_matrix=matrix.copy()\n",
        "          for s_num,s in enumerate(sample):\n",
        "                t_matrix.remove(t_matrix[s-s_num])\n",
        "          distancee = distance(t_matrix,compare_matrix)\n",
        "          distancee=np.mean(distancee)\n",
        "          t_matrix.append(distancee)\n",
        "          all_t_matrixes.append(t_matrix)\n",
        "    for a in all_t_matrixes:\n",
        "          dis_value.append(a[-1:])\n",
        "    selected_matrix=all_t_matrixes[np.argmin(dis_value)]\n",
        "    selected_matrix=selected_matrix[0:-1]\n",
        "\n",
        "    return selected_matrix\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def equalize_matrix(matrix,number,compare_matrix):\n",
        "    e_matrix=[]\n",
        "    for place in range(len(matrix)):\n",
        "          if place == len(matrix)-1:\n",
        "                break\n",
        "          e_matrix.append((matrix[place]+matrix[place+1])/2)\n",
        "          \n",
        "    for end_place in range(number) :\n",
        "          e_matrix.append(matrix[len(matrix)-1])\n",
        "          \n",
        "    for start_place in range(number) :\n",
        "          e_matrix.insert(0,matrix[0])  \n",
        "         \n",
        "    selected_matrix = best_places(e_matrix,number,matrix,compare_matrix)\n",
        "    return selected_matrix\n",
        "\n",
        "  \n",
        "      \n",
        "\n",
        "def best_places(e_matrix,number,matrix,compare_matrix):\n",
        "    import random\n",
        "    import math\n",
        "    import numpy as np\n",
        "    conditions = math.factorial(len(e_matrix))/(math.factorial(number)*math.factorial(len(e_matrix)-number))\n",
        "    samples=[]\n",
        "    all_t_matrixes=[]\n",
        "    dis_value=[]\n",
        "    num_e_matrix=[i for i in range(len(e_matrix))]\n",
        "    while(True):\n",
        "          x=random.sample(num_e_matrix,number)\n",
        "          x.sort()\n",
        "          if x not in samples:\n",
        "                samples.append(x)\n",
        "          if len(samples)==conditions:\n",
        "                break\n",
        "    for sample in samples:\n",
        "          t_matrix=matrix.copy()\n",
        "          first_numbers=[n for n in range(number)]\n",
        "          for s_num,s in enumerate(sample):\n",
        "              if s in first_numbers:\n",
        "                  t_matrix.insert(s,e_matrix[s])\n",
        "              else:\n",
        "                  t_matrix.insert(s+1+s_num-number,e_matrix[s])\n",
        "          distancee = distance(t_matrix,compare_matrix)\n",
        "          distancee=np.mean(distancee)\n",
        "          t_matrix.append(distancee)\n",
        "          all_t_matrixes.append(t_matrix)\n",
        "    for a in all_t_matrixes:\n",
        "          dis_value.append(a[-1:])\n",
        "    selected_matrix=all_t_matrixes[np.argmin(dis_value)]\n",
        "    selected_matrix=selected_matrix[0:-1]\n",
        "    return selected_matrix\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzKuboHhUH4Y"
      },
      "source": [
        "def distance(a,b):\n",
        "  if len(a)==len(b):\n",
        "      d= len(a)\n",
        "      dis_matrix=[]\n",
        "      for num in range(d):\n",
        "          single_dis=(((a[num][0]-b[num][0])**2)+((a[num][1]-b[num][1])**2))**0.5\n",
        "          dis_matrix.append(single_dis)\n",
        "      return(dis_matrix)\n",
        "      \n",
        "  else:\n",
        "      raise NameError('given lists dont have same length')\n",
        "      \n",
        "# Interpolation for equalization\n",
        "def interpolate(t,a):\n",
        "  ta= len(t)-len(a)\n",
        "  at= len(a)-len(t)\n",
        "  if ta>0 and ta<=5:\n",
        "        a=equalize_matrix(a,ta,t)\n",
        "  elif at>0 and at<=5:\n",
        "        t=equalize_matrix(t,at,a)\n",
        "  elif ta >= 6 or at >= 6:\n",
        "      t='stop'\n",
        "      a='stop'\n",
        "  else:\n",
        "        pass\n",
        "  \n",
        "  return[t,a]\n",
        "  \n",
        "  \n",
        "  \n",
        "def equalize_matrix(matrix,number,compare_matrix):\n",
        "    e_matrix=[]\n",
        "    for place in range(len(matrix)):\n",
        "          if place == len(matrix)-1:\n",
        "                break\n",
        "          e_matrix.append([(matrix[place][0]+matrix[place+1][0])/2,(matrix[place][1]+matrix[place+1][1])/2])\n",
        "    for end_place in range(number) :\n",
        "          e_matrix.append(matrix[len(matrix)-1])\n",
        "    selected_matrix = best_places(e_matrix,number,matrix,compare_matrix)\n",
        "    return selected_matrix\n",
        "  \n",
        "      \n",
        "\n",
        "def best_places(e_matrix,number,matrix,compare_matrix):\n",
        "    import random\n",
        "    import math\n",
        "    import numpy as np\n",
        "    conditions = math.factorial(len(e_matrix))/(math.factorial(number)*math.factorial(len(e_matrix)-number))\n",
        "    samples=[]\n",
        "    all_t_matrixes=[]\n",
        "    dis_value=[]\n",
        "    num_e_matrix=[i for i in range(len(e_matrix))]\n",
        "    while(True):\n",
        "          x=random.sample(num_e_matrix,number)\n",
        "          x.sort()\n",
        "          if x not in samples:\n",
        "                samples.append(x)\n",
        "          if len(samples)==conditions:\n",
        "                break\n",
        "    for sample in samples:\n",
        "          t_matrix=matrix.copy()\n",
        "          for s in sample:\n",
        "                t_matrix.insert(s+1,e_matrix[s])\n",
        "          distancee = distance(t_matrix,compare_matrix)\n",
        "          distancee=np.mean(distancee)\n",
        "          t_matrix.append(distancee)\n",
        "          all_t_matrixes.append(t_matrix)\n",
        "    for a in all_t_matrixes:\n",
        "          dis_value.append(a[-1:])\n",
        "    selected_matrix=all_t_matrixes[np.argmin(dis_value)]\n",
        "    selected_matrix=selected_matrix[0:-1]\n",
        "    return selected_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jh6sJuEpZ9U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a94720c2-d645-4c55-e396-8305d190679a"
      },
      "source": [
        "t=[[1,2],[4,5]]\n",
        "a=[[1,2],[3,4],[4,5]]\n",
        "interpolate(t,a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[1, 2], [2.5, 3.5], [4, 5]], [[1, 2], [3, 4], [4, 5]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWfqbZZ4Wdkw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7eaaef3-570f-401b-f0f9-56de6c5fa502"
      },
      "source": [
        "equalize([2,5],[2,4,5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 3.5, 5], [2, 4, 5]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    }
  ]
}